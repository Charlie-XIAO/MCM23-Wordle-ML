{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "List and describe some other interesting features of this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the word difficulty classification data and break down words into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./dataset/difficulty_classification.xlsx\", index_col=0, usecols=\"A,B,C\")\n",
    "df_chars = pd.DataFrame(index=df.index, data=[ch for ch in df[\"word\"].apply(func=list).values], columns=[\"ch1\", \"ch2\", \"ch3\", \"ch4\", \"ch5\"])\n",
    "df[df_chars.columns] = df_chars\n",
    "del df[\"word\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data into a boolean values list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransactionEncoder()\n",
    "df_vals = df.values\n",
    "df_vals[:, 0] = df_vals[:, 0].astype(\"str\")\n",
    "encoder_arr = encoder.fit(df_vals).transform(df_vals)\n",
    "df_arr = pd.DataFrame(encoder_arr, columns=encoder.columns_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Apriori algorithm to discover frequent patterns of length 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'e', 'a']\n",
      "['0', 'r', 'a']\n",
      "['0', 'r', 'e']\n",
      "['1', 'e', 't']\n",
      "['4', 'e', 'a']\n",
      "['s', '4', 'e']\n",
      "['4', 'e', 't']\n"
     ]
    }
   ],
   "source": [
    "itemsets = apriori(df_arr, min_support=0.04, use_colnames=True)\n",
    "itemsets[\"length\"] = itemsets[\"itemsets\"].apply(lambda x: len(x))\n",
    "for _, itemset, _  in itemsets[itemsets.length == 3].values:\n",
    "    itemlist = list(itemset)\n",
    "    if itemlist[0].isdigit() or itemlist[1].isdigit() or itemlist[2].isdigit():\n",
    "        print(itemlist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Apriori algorithm to discover frequent patterns of length 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'r', 'e', 'a']\n"
     ]
    }
   ],
   "source": [
    "itemsets = apriori(df_arr, min_support=0.02, use_colnames=True)\n",
    "itemsets[\"length\"] = itemsets[\"itemsets\"].apply(lambda x: len(x))\n",
    "for _, itemset, _  in itemsets[itemsets.length == 4].values:\n",
    "    itemlist = list(itemset)\n",
    "    if itemlist[0].isdigit() or itemlist[1].isdigit() or itemlist[2].isdigit() or itemlist[3].isdigit():\n",
    "        print(itemlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fec3e7d24dd26d4741ecd66e0fb7094705806a0205b22c2a5c5101ff21c51c58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
